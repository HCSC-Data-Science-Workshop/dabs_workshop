{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd7ce9b5-ddf8-4333-9102-e1baa4eb41af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Challenger model validation\n",
    "\n",
    "This notebook performs validation tasks on the candidate __Challenger__ model.\n",
    "\n",
    "It goes through a few steps to validate the model before labelling it (by setting its alias) to `Challenger`.\n",
    "\n",
    "When organizations first start to put MLOps processes in place, they should consider having a \"human-in-the-loop\" to perform visual analyses to validate models before promoting them. As they get more familiar with the process, they can consider automating the steps in a __Workflow__ . The benefits of automation is to ensure that these validation checks are systematically performed before new models are integrated into inference pipelines or deployed for realtime serving. Of course, organizations can opt to retain a \"human-in-the-loop\" in any part of the process and put in place the degree of automation that suits its business needs.\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/banners/mlflow-uc-end-to-end-advanced-4.png?raw=true\" width=\"1200\">\n",
    "\n",
    "*Note: In a typical mlops setup, this would run as part of an automated job to validate a new model. We'll run this demo as an interactive notebook.*\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable the collection or the tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=984752964297111&notebook=%2F02-mlops-advanced%2F04_challenger_validation&demo_name=mlops-end2end&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fmlops-end2end%2F02-mlops-advanced%2F04_challenger_validation&version=1&user_hash=a3692eff9e5299c6a85c26f2dc27b2e2000517102cea778a7cc80efff9afb355\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ecd7ee-e2f7-42ab-9ec0-e5a260f43f00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## General Validation Checks\n",
    "\n",
    "<!--img style=\"float: right\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/churn-mlflow-webhook-1.png\" width=600 -->\n",
    "\n",
    "In the context of MLOps, there are more tests than simply how accurate a model will be.  To ensure the stability of our ML system and compliance with any regulatory requirements, we will subject each model added to the registry to a series of validation checks.  These include, but are not limited to:\n",
    "<br>\n",
    "* __Model documentation__\n",
    "* __Inference on production data__\n",
    "* __Champion-Challenger testing to ensure that business KPIs are acceptable__\n",
    "\n",
    "In this notebook, we explore some approaches to performing these tests, and how we can add metadata to our models by tagging if they have passed a given test.\n",
    "\n",
    "This part is typically specific to your line of business and quality requirements.\n",
    "\n",
    "For each test, we'll add information using tags to know what has been validated in the model. We can also add Comments to a model if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70f46611-3caa-447a-aee3-6d1d11439cdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet mlflow==2.19 databricks-feature-engineering==0.8.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a023da17-9e43-458b-91e2-b90968fcc30c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MLflow experiment name.\n",
    "dbutils.widgets.text(\n",
    "    \"experiment_name\",\n",
    "    \"/advanced_mlops_churn_experiment\",\n",
    "    label=\"Experiment Name\",\n",
    ")\n",
    "\n",
    "# Unity Catalog registered model name to use for the trained mode.\n",
    "dbutils.widgets.text(\n",
    "    \"model_name\", \n",
    "    \"dev.koeppen_dabs_demo.advanced_mlops_churn_model\", \n",
    "    label=\"Full (Three-Level) Model Name\"\n",
    ")\n",
    "\n",
    "\n",
    "# Feature table to store the computed features.\n",
    "dbutils.widgets.text(\n",
    "    \"advanced_churn_label_table\",\n",
    "    \"dev.koeppen_dabs_demo.advanced_churn_label_table\",\n",
    "    label=\"Label Table\",\n",
    ")\n",
    "\n",
    "# Feature table to store the computed features.\n",
    "dbutils.widgets.text(\n",
    "    \"advanced_churn_feature_table\",\n",
    "    \"dev.koeppen_dabs_demo.advanced_churn_feature_table\",\n",
    "    label=\"Feature Table\",\n",
    ")\n",
    "\n",
    "# Feature table to store the computed features.\n",
    "dbutils.widgets.text(\n",
    "    \"avg_price_increase\",\n",
    "    \"dev.koeppen_dabs_demo.avg_price_increase\",\n",
    "    label=\"Avg Price Increase Function\",\n",
    ")\n",
    "\n",
    "# Feature table to store the computed features.\n",
    "dbutils.widgets.text(\n",
    "    \"model_alias\",\n",
    "    \"challenger\",\n",
    "    label=\"Model Alias\",\n",
    ")\n",
    "\n",
    "# Feature table to store the computed features.\n",
    "dbutils.widgets.text(\n",
    "    \"model_info_table\",\n",
    "    \"dev.koeppen_dabs_demo.model_info_table\",\n",
    "    label=\"Model Information Table\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b557232-d052-471e-8b41-4a400317a6b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "advanced_churn_label_table = dbutils.widgets.get(\"advanced_churn_label_table\")\n",
    "advanced_churn_feature_table = dbutils.widgets.get(\"advanced_churn_feature_table\")\n",
    "experiment_name = dbutils.widgets.get(\"experiment_name\")\n",
    "model_name = dbutils.widgets.get(\"model_name\")\n",
    "avg_price_increase=dbutils.widgets.get(\"avg_price_increase\")\n",
    "model_alias=dbutils.widgets.get(\"model_alias\")\n",
    "model_info_table=dbutils.widgets.get(\"model_info_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8c4f63f-b5d9-4c3d-a12e-e3d25d6b4ac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_schema = advanced_churn_feature_table.split(\".\")[0]\n",
    "output_database = advanced_churn_feature_table.split(\".\")[1]\n",
    "spark.sql(f\"USE CATALOG {output_schema}\");\n",
    "spark.sql(f\"USE SCHEMA {output_database}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1f6202-3e7e-4fbc-a922-afaf071c4342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Getting Model Information based on which Alias we're wanting to Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "776c8d00-437e-425d-84e0-c47e4337c99e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "model_details = client.get_model_version_by_alias(model_name, model_alias)\n",
    "model_version = int(model_details.version)\n",
    "model_uri = model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "# Determine modeling method via tag\n",
    "modeling_method = model_details.tags.get(\"modeling_method\", \"\")\n",
    "\n",
    "print(f\"Validating {model_alias} model for {model_name} on model version {model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6717ce33-6ec0-4c47-bb3e-e25833abff00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load label table\n",
    "labels_df = spark.table(advanced_churn_label_table)\n",
    "# Load feature table\n",
    "features_df = spark.table(advanced_churn_feature_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56328942-d471-44e9-9cec-e16bda2fc02c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow import pyfunc\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Load model version via alias\n",
    "client = MlflowClient()\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# AutoML models are often exported as MLflow pyfunc models which is designed to accept input data as pandas DFs\n",
    "if modeling_method == \"AutoML\":\n",
    "    print(\"Using pyfunc for AutoML scoring...\")\n",
    "\n",
    "    model = pyfunc.load_model(model_uri)\n",
    "\n",
    "    # Join labels + features\n",
    "    features_df = features_df.withColumn(\"avg_price_increase\",(F.col(\"monthly_charges\") - (F.col(\"total_charges\") / F.col(\"tenure\"))))\n",
    "    joined_df = labels_df.join(features_df, on=[\"customer_id\", \"transaction_ts\"], how=\"inner\")\n",
    "\n",
    "    # Select only the columns the model expects\n",
    "    input_schema = model.metadata.get_input_schema()\n",
    "    expected_cols = [col.name for col in input_schema.inputs]\n",
    "\n",
    "    validation_df = joined_df\n",
    "    pdf_features = validation_df.select(*expected_cols).toPandas()\n",
    "    # Convert all float64 columns to float32 to match model input schema\n",
    "    pdf_features = pdf_features.astype({col: \"float32\" for col in pdf_features.select_dtypes(\"float64\").columns})\n",
    "\n",
    "    pdf_labels = validation_df.select(\"churn\").toPandas()\n",
    "\n",
    "    predictions = model.predict(pdf_features)\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1 = f1_score(pdf_labels, predictions, pos_label=\"Yes\")\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Using Feature Store batch scoring...\")\n",
    "\n",
    "    model_uri_with_alias = f\"models:/{model_name}@{model_alias}\"\n",
    "\n",
    "    # Ensure predictions are numeric\n",
    "    scored_df = fe.score_batch(df=labels_df, model_uri=model_uri_with_alias, result_type=\"string\")\n",
    "\n",
    "    # Convert label + prediction to DoubleType for evaluator\n",
    "    scored_df = (\n",
    "        scored_df\n",
    "        .withColumn(\"prediction\", F.when(F.col(\"prediction\") == \"Yes\", 1.0).otherwise(0.0))\n",
    "        .withColumn(\"churn\", F.when(F.col(\"churn\") == \"Yes\", 1.0).otherwise(0.0))\n",
    "    )\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"churn\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    f1 = evaluator.evaluate(scored_df)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a71fe08e-8989-4bea-8720-ad183c3ab592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_spark = spark.createDataFrame([(\n",
    "  model_name,\n",
    "  model_version,\n",
    "  float(round(f1, 4)),\n",
    "  model_alias, \n",
    "  modeling_method,\n",
    "  datetime.now()\n",
    ")], [\"model_name\", \"model_version\", \"f1_score\",\"model_alias\",\"modeling_method\",\"validation_timestamp\"]).write.mode(\"append\").saveAsTable(model_info_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c57b990d-d79e-4960-9c79-fcdfb5759b05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "validation",
   "widgets": {
    "advanced_churn_feature_table": {
     "currentValue": "dev.koeppen_dabs_demo.advanced_churn_feature_table",
     "nuid": "9a98695b-ae5a-4bd6-9a9c-e788a82c6b92",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev.koeppen_dabs_demo.advanced_churn_feature_table",
      "label": "Feature Table",
      "name": "advanced_churn_feature_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev.koeppen_dabs_demo.advanced_churn_feature_table",
      "label": "Feature Table",
      "name": "advanced_churn_feature_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "advanced_churn_label_table": {
     "currentValue": "dev.koeppen_dabs_demo.advanced_churn_label_table",
     "nuid": "efa5d2a8-d634-4267-b887-e3d0ee4aac8b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev.koeppen_dabs_demo.advanced_churn_label_table",
      "label": "Label Table",
      "name": "advanced_churn_label_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev.koeppen_dabs_demo.advanced_churn_label_table",
      "label": "Label Table",
      "name": "advanced_churn_label_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "avg_price_increase": {
     "currentValue": "dev.koeppen_dabs_demo.avg_price_increase",
     "nuid": "e122c913-2f24-4bf6-9e2a-cf632ed9787a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev.koeppen_dabs_demo.avg_price_increase",
      "label": "Avg Price Increase Function",
      "name": "avg_price_increase",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev.koeppen_dabs_demo.avg_price_increase",
      "label": "Avg Price Increase Function",
      "name": "avg_price_increase",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "experiment_name": {
     "currentValue": "/advanced_mlops_churn_experiment",
     "nuid": "3e6c1262-90df-4f36-8a7c-013a36498329",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/advanced_mlops_churn_experiment",
      "label": "Experiment Name",
      "name": "experiment_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/advanced_mlops_churn_experiment",
      "label": "Experiment Name",
      "name": "experiment_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_alias": {
     "currentValue": "challenger",
     "nuid": "ad3cfec9-7817-4b1c-a477-17452ec61a36",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "challenger",
      "label": "Model Alias",
      "name": "model_alias",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "challenger",
      "label": "Model Alias",
      "name": "model_alias",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_info_table": {
     "currentValue": "dev.koeppen_dabs_demo.model_info_table",
     "nuid": "f77853e5-61c8-40e4-a14f-f784e647cb86",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev.koeppen_dabs_demo.model_info_table",
      "label": "Model Information Table",
      "name": "model_info_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev.koeppen_dabs_demo.model_info_table",
      "label": "Model Information Table",
      "name": "model_info_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_name": {
     "currentValue": "dev.koeppen_dabs_demo.advanced_mlops_churn_model",
     "nuid": "58c134f9-1555-46af-a45c-7fb02fb5cd65",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev.koeppen_dabs_demo.advanced_mlops_churn_model",
      "label": "Full (Three-Level) Model Name",
      "name": "model_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev.koeppen_dabs_demo.advanced_mlops_churn_model",
      "label": "Full (Three-Level) Model Name",
      "name": "model_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

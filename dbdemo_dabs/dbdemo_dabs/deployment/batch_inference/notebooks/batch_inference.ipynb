{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a02d9832-5fbe-4c9a-9189-904a7e2a957a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Churn Prediction Model Inference\n",
    "\n",
    "## Inference with the Champion model\n",
    "\n",
    "Models in Unity Catalog can be loaded for use in batch inference pipelines. Generated predictions would be used to advise on customer retention strategies or be used for analytics. The model in use is the __@Champion__ model, and we will load it for use in our pipeline.\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/banners/mlflow-uc-end-to-end-advanced-5.png?raw=true\" width=\"1200\">\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=984752964297111&notebook=%2F02-mlops-advanced%2F05_batch_inference&demo_name=mlops-end2end&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fmlops-end2end%2F02-mlops-advanced%2F05_batch_inference&version=1&user_hash=a3692eff9e5299c6a85c26f2dc27b2e2000517102cea778a7cc80efff9afb355\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35d3230b-df5f-40f2-bb8f-9469f9f2b640",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install MLflow version for model lineage in UC [for MLR < 15.2]"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet mlflow==2.19 databricks-feature-engineering==0.8.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ac02d1f-272f-4e4a-b628-926dc7300af1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature table to store the computed features.\n",
    "dbutils.widgets.text(\n",
    "    \"inference_df\",\n",
    "    \"dev.koeppen_dabs_demo.advanced_churn_inference_table\",\n",
    "    label=\"Inference Table\",\n",
    ")\n",
    "\n",
    "# Feature table to store the computed features.\n",
    "dbutils.widgets.text(\n",
    "    \"model_name\",\n",
    "    \"dev.koeppen_dabs_demo.advanced_mlops_churn_model\",\n",
    "    label=\"experiment_name\",\n",
    ")\n",
    "\n",
    "# Feature table to store the computed features.\n",
    "dbutils.widgets.text(\n",
    "    \"advanced_churn_inference_results\",\n",
    "    \"dev.koeppen_dabs_demo.advanced_churn_inference_results\",\n",
    "    label=\"Inference Results Table\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a4e0a07-eb5a-4623-8a0a-73b4246ac35c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inference_df=dbutils.widgets.get(\"inference_df\")\n",
    "model_name=dbutils.widgets.get(\"model_name\")\n",
    "advanced_churn_inference_results=dbutils.widgets.get(\"advanced_churn_inference_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99c02274-4941-4374-b7e6-d23966bbba82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33603db5-b1c2-4ede-a847-5bc3def8112f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Batch inference on the Champion model\n",
    "\n",
    "We are ready to run inference on the Champion model. We will leverage the feature engineering client's `score_batch` method and generate predictions for our customer records.\n",
    "\n",
    "For simplicity, we assume that features have been pre-computed for all new customer records and already stored in a feature table. These are typically done by separate feature engineering pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c58dcc54-87be-49ae-ac99-d9e9274a7503",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "champion_model_details = client.get_model_version_by_alias(model_name, \"Champion\")\n",
    "champion_model_version = int(champion_model_details.version)\n",
    "champion_run_info = client.get_run(run_id=champion_model_details.run_id)\n",
    "\n",
    "print(f\"Champion model for {model_name} is model version {champion_model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e67b10c-8fdf-4c5a-9f4d-df3a94d0e43b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "In a python notebook"
    }
   },
   "outputs": [],
   "source": [
    "# Batch score\n",
    "preds_df = fe.score_batch(df=inference_df, model_uri=model_uri, result_type=\"string\")\n",
    "display(preds_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fde52aca-e43d-4793-903a-62bef08d1228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "That's it! Our data can now be saved as a table and reused by the Data Analyst / Marketing team to take special action and reduce Churn risk on these customers!\n",
    "\n",
    "Your data will also be available within Genie to answer any churn-related question using plain text English!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "144f9564-467f-46b5-8242-2f7271cc83d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Save the predictions for monitoring\n",
    "\n",
    "Since we want to monitor the model and its predictions over time, we will save the predictions, along with information on the model used to produce them. This table can then be monitored for feature drift and prediction drift.\n",
    "\n",
    "Note that this table does not have the ground truth labels. These are usually collected and made available over time, and in many cases, may not even be available! However, this does not stop us from monitoring the data for drift, as that alone may be a sign that the model has to be retrained.\n",
    "\n",
    "The table displayed below is saved into `advanced_churn_offline_inference`. It includes the model version used for scoring, the model alias, the predictions, and the timestamp when the inference was made. It does not contain any labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d211fb6d-6c03-49c2-8d6f-c116ad59ed07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from datetime import datetime\n",
    "client = MlflowClient()\n",
    "\n",
    "model = client.get_registered_model(name=model_name)\n",
    "model_version = int(client.get_model_version_by_alias(name=model_name, alias=\"Champion\").version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1dd1671-d885-4c31-bc8f-ec4c03236169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "offline_inference_df = preds_df.withColumn(\"model_name\", F.lit(model_name)) \\\n",
    "                              .withColumn(\"model_version\", F.lit(model_version)) \\\n",
    "                              .withColumn(\"model_alias\", F.lit(\"Champion\")) \\\n",
    "                              .withColumn(\"inference_timestamp\", F.lit(datetime.now()- timedelta(days=2)))\n",
    "\n",
    "offline_inference_df.write.mode(\"append\") \\\n",
    "                    .saveAsTable(advanced_churn_inference_results)\n",
    "\n",
    "display(offline_inference_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f609f5e-349a-408e-b942-93295d50b57d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Congratulations! You have successfully used the model for batch inference.\n",
    "\n",
    "Let's look at how we can deploy this model as a REST API endpoint for real-time inference.\n",
    "\n",
    "Next:  [Serve the features and model in real-time]($./06_serve_features_and_model)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "batch_inference",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
